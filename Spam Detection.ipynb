{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data/Youtube01-Psy.csv\",encoding = \"ISO-8859-1\")\n",
    "df2 = pd.read_csv(\"data/Youtube02-KatyPerry.csv\",encoding = \"ISO-8859-1\")\n",
    "df3 = pd.read_csv(\"data/Youtube03-LMFAO.csv\",encoding = \"ISO-8859-1\")\n",
    "df4 = pd.read_csv(\"data/Youtube04-Eminem.csv\",encoding = \"ISO-8859-1\")\n",
    "df5 = pd.read_csv(\"data/Youtube05-Shakira.csv\",encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train on the df1,df2,df3,df4 and test on df5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df5['CLASS']\n",
    "df5.drop('CLASS',axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z13lgffb5w3ddx1ul22qy1wxspy5cpkz504</td>\n",
       "      <td>dharma pal</td>\n",
       "      <td>2015-05-29T02:30:18.971000</td>\n",
       "      <td>Nice songï»¿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z123dbgb0mqjfxbtz22ucjc5jvzcv3ykj</td>\n",
       "      <td>Tiza Arellano</td>\n",
       "      <td>2015-05-29T00:14:48.748000</td>\n",
       "      <td>I love song ï»¿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z12quxxp2vutflkxv04cihggzt2azl34pms0k</td>\n",
       "      <td>PrÃ¬Ã±Ã§eÅÅ ÃliÅ ÅÃ¸vÃª DÃ¸mÃ­Ã±Ã¸ MÃ¢Äi...</td>\n",
       "      <td>2015-05-28T21:00:08.607000</td>\n",
       "      <td>I love song ï»¿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z12icv3ysqvlwth2c23eddlykyqut5z1h</td>\n",
       "      <td>Eric Gonzalez</td>\n",
       "      <td>2015-05-28T20:47:12.193000</td>\n",
       "      <td>860,000,000 lets make it first female to reach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z133stly3kete3tly22petvwdpmghrlli</td>\n",
       "      <td>Analena LÃ³pez</td>\n",
       "      <td>2015-05-28T17:08:29.827000</td>\n",
       "      <td>shakira is best for worldcupï»¿</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              COMMENT_ID  \\\n",
       "0    z13lgffb5w3ddx1ul22qy1wxspy5cpkz504   \n",
       "1      z123dbgb0mqjfxbtz22ucjc5jvzcv3ykj   \n",
       "2  z12quxxp2vutflkxv04cihggzt2azl34pms0k   \n",
       "3      z12icv3ysqvlwth2c23eddlykyqut5z1h   \n",
       "4      z133stly3kete3tly22petvwdpmghrlli   \n",
       "\n",
       "                                              AUTHOR  \\\n",
       "0                                         dharma pal   \n",
       "1                                      Tiza Arellano   \n",
       "2  PrÃ¬Ã±Ã§eÅÅ ÃliÅ ÅÃ¸vÃª DÃ¸mÃ­Ã±Ã¸ MÃ¢Äi...   \n",
       "3                                      Eric Gonzalez   \n",
       "4                                     Analena LÃ³pez   \n",
       "\n",
       "                         DATE  \\\n",
       "0  2015-05-29T02:30:18.971000   \n",
       "1  2015-05-29T00:14:48.748000   \n",
       "2  2015-05-28T21:00:08.607000   \n",
       "3  2015-05-28T20:47:12.193000   \n",
       "4  2015-05-28T17:08:29.827000   \n",
       "\n",
       "                                             CONTENT  \n",
       "0                                       Nice songï»¿  \n",
       "1                                    I love song ï»¿  \n",
       "2                                    I love song ï»¿  \n",
       "3  860,000,000 lets make it first female to reach...  \n",
       "4                    shakira is best for worldcupï»¿  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [df1,df2,df3,df4]\n",
    "final_df = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1586, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .ï»¿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    COMMENT_ID            AUTHOR  \\\n",
       "0  LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU         Julius NM   \n",
       "1  LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A       adam riyati   \n",
       "2  LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8  Evgeny Murashkin   \n",
       "3          z13jhp0bxqncu512g22wvzkasxmvvzjaz04   ElNino Melendez   \n",
       "4          z13fwbwp1oujthgqj04chlngpvzmtt3r3dw            GsMega   \n",
       "\n",
       "                  DATE                                            CONTENT  \\\n",
       "0  2013-11-07T06:20:48  Huh, anyway check out this you[tube] channel: ...   \n",
       "1  2013-11-07T12:37:15  Hey guys check out my new channel and our firs...   \n",
       "2  2013-11-08T17:34:21             just for test I have to say murdev.com   \n",
       "3  2013-11-09T08:28:43  me shaking my sexy ass on my channel enjoy ^_^...   \n",
       "4  2013-11-10T16:05:38          watch?v=vtaRGgvGtWQ   Check this out .ï»¿   \n",
       "\n",
       "   CLASS  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Spam Classification'}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_df['CLASS'].value_counts().plot.bar(title='Spam Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = final_df['CONTENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1586x4169 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 20570 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(comment)\n",
    "X_train_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1586, 4169)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below lines of code are used to achieve it.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/hyperopt/hyperopt-sklearn.git\n",
      "  Cloning https://github.com/hyperopt/hyperopt-sklearn.git to c:\\users\\sivam\\appdata\\local\\temp\\pip-req-build-eb9aje43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/hyperopt/hyperopt-sklearn.git 'C:\\Users\\sivam\\AppData\\Local\\Temp\\pip-req-build-eb9aje43'\n",
      "  ERROR: Error [WinError 2] The system cannot find the file specified while executing command git clone -q https://github.com/hyperopt/hyperopt-sklearn.git 'C:\\Users\\sivam\\AppData\\Local\\Temp\\pip-req-build-eb9aje43'\n",
      "ERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/hyperopt/hyperopt-sklearn.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf-svm', SGDClassifier(loss='modified_huber', penalty='l2',\n",
    "                     alpha=1e-3, random_state=42)),])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf-svm',\n",
       "                 SGDClassifier(alpha=0.001, loss='modified_huber',\n",
       "                               random_state=42))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = final_df[\"CLASS\"]\n",
    "text_clf_svm.fit(comment,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1586,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "predicted_svm = text_clf_svm.predict(df5['CONTENT'])\n",
    "print(predicted_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9216216216216216"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test, predicted_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9123867069486404"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(test, predicted_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"data/YoutubeSpamMergedData.csv\")\n",
    "df_data = df[[\"CONTENT\",\"CLASS\"]]\n",
    "# Features and Labels\n",
    "df_x = df_data['CONTENT']\n",
    "df_y = df_data.CLASS\n",
    "# Extract Feature With CountVectorizer\n",
    "corpus = df_x\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus) # Fit the Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df_y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Accuracy score for MNB:  91.95046439628483 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_NB = MultinomialNB()\n",
    "clf_NB.fit(X_train,y_train)\n",
    "clf_NB.score(X_test,y_test)\n",
    "predictions = clf_NB.predict(X_test)\n",
    "val1 = (accuracy_score(y_test, predictions)*100)\n",
    "print(\"*Accuracy score for MNB: \", val1, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Accuracy score for SVM:  93.96284829721363 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVM = SVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "SVM.score(X_test,y_test)\n",
    "predictions = SVM.predict(X_test)\n",
    "val2 = (accuracy_score(y_test, predictions)*100)\n",
    "print(\"*Accuracy score for SVM: \", val2, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bring some raw data.\n",
    "frequencies = [val1,val2]\n",
    "\n",
    "# In my original code I create a series and run on that,\n",
    "# so for consistency I create a series from the list.\n",
    "freq_series = pd.Series.from_array(frequencies)\n",
    "\n",
    "x_labels = ['MNB','SVM']\n",
    "\n",
    "# Plot the figure.\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = freq_series.plot(kind='bar')\n",
    "ax.set_title('Evaluation of ML')\n",
    "ax.set_xlabel('Classifier!')\n",
    "ax.set_ylabel('Accuracy Range')\n",
    "ax.set_xticklabels(x_labels)\n",
    "\n",
    "\n",
    "def add_value_labels(ax, spacing=5):\n",
    "    \"\"\"Add labels to the end of each bar in a bar chart.\n",
    "\n",
    "    Arguments:\n",
    "        ax (matplotlib.axes.Axes): The matplotlib object containing the axes\n",
    "            of the plot to annotate.\n",
    "        spacing (int): The distance between the labels and the bars.\n",
    "    \"\"\"\n",
    "\n",
    "    # For each bar: Place a label\n",
    "    for rect in ax.patches:\n",
    "        # Get X and Y placement of label from rect.\n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2\n",
    "\n",
    "        # Number of points between bar and label. Change to your liking.\n",
    "        space = spacing\n",
    "        # Vertical alignment for positive values\n",
    "        va = 'bottom'\n",
    "\n",
    "        # If value of bar is negative: Place label below bar\n",
    "        if y_value < 0:\n",
    "            # Invert space to place label below\n",
    "            space *= -1\n",
    "            # Vertically align label at top\n",
    "            va = 'top'\n",
    "\n",
    "        # Use Y value as label and format number with one decimal place\n",
    "        label = \"{:.1f}\".format(y_value)\n",
    "\n",
    "        # Create annotation\n",
    "        ax.annotate(\n",
    "            label,                      # Use `label` as label\n",
    "            (x_value, y_value),         # Place label at end of the bar\n",
    "            xytext=(0, space),          # Vertically shift label by `space`\n",
    "            textcoords=\"offset points\", # Interpret `xytext` as offset in points\n",
    "            ha='center',                # Horizontally center label\n",
    "            va=va)                      # Vertically align label differently for\n",
    "                                        # positive and negative values.\n",
    "\n",
    "\n",
    "# Call the function above. All the magic happens there.\n",
    "add_value_labels(ax)\n",
    "plt.show()\n",
    "#plt.savefig(\"image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:9000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [09/Oct/2021 11:58:18] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [09/Oct/2021 11:58:18] \"\u001b[37mGET /static/css/styles.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [09/Oct/2021 11:58:18] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask,render_template,url_for,request\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "from werkzeug.wrappers import Request, Response\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "\treturn render_template('home.html')\n",
    "\n",
    "@app.route('/predict',methods=['POST'])\n",
    "def predict():\n",
    "\tdf= pd.read_csv(\"data/YoutubeSpamMergedData.csv\")\n",
    "\tdf_data = df[[\"CONTENT\",\"CLASS\"]]\n",
    "\t# Features and Labels\n",
    "\tdf_x = df_data['CONTENT']\n",
    "\tdf_y = df_data.CLASS\n",
    "    # Extract Feature With CountVectorizer\n",
    "\tcorpus = df_x\n",
    "\tcv = CountVectorizer()\n",
    "\tX = cv.fit_transform(corpus) # Fit the Data\n",
    "\tfrom sklearn.model_selection import train_test_split\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, df_y, test_size=0.33, random_state=42)\n",
    "\t#Naive Bayes Classifier\n",
    "\tfrom sklearn.naive_bayes import MultinomialNB\n",
    "\tclf = SVC()\n",
    "\tclf.fit(X_train,y_train)\n",
    "\tclf.score(X_test,y_test)\n",
    "\t#Alternative Usage of Saved Model\n",
    "\t# ytb_model = open(\"naivebayes_spam_model.pkl\",\"rb\")\n",
    "\t# clf = joblib.load(ytb_model)\n",
    "\n",
    "\tif request.method == 'POST':\n",
    "\t\tcomment = request.form['comment']\n",
    "\t\tdata = [comment]\n",
    "\t\tvect = cv.transform(data).toarray()\n",
    "\t\tmy_prediction = clf.predict(vect)\n",
    "\treturn render_template('result.html',prediction = my_prediction)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('localhost', 9000, app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
